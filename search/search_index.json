{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Wiki Index P = NP P = NP","title":"Wiki Index"},{"location":"#wiki-index","text":"P = NP P = NP","title":"Wiki Index"},{"location":"studies/","text":"Study Board Math Index Programming Index Binary Trees","title":"Study Board"},{"location":"studies/#study-board","text":"","title":"Study Board"},{"location":"studies/#math","text":"Index","title":"Math"},{"location":"studies/#programming","text":"Index Binary Trees","title":"Programming"},{"location":"studies/math/","text":"","title":"Index"},{"location":"studies/programming/","text":"","title":"Index"},{"location":"studies/programming/data_structures/binary_trees/","text":"Binary Trees A binary tree is a data structure where each node has 0, 1 or two children, referred to as left child and right child . A node without a parent is called a root , nodes without children are called leaves . Each node has 0-N ancestors , which refers to the parent chain up to the root, and descendants , in the direction of the leaves. The depth is the level of the node in comparison to the roots (root is lv1, both its children are lv2) and so on. Types of Binary Trees Complete Tree: is a tree that is filled (as in, each node has at 2 nodes except for the leaves), and all the leaves in the last level are as far left as possible. graph TD 1 --> 2 1 --> 3 2 --> 4 2 --> 5 3 --> 6 3 --> 7 4 --> 8 Full Tree: is a tree in which every node has either 0 or 2 children. graph TD 1 --> 2 1 --> 3 2 --> 4 2 --> 5 3 --> 6 3 --> 7 Which can be represented with the following: pub type Child < T > = Option < Box < Node < T >>> ; #[derive(Clone, Debug)] pub struct Node < T : Clone + Copy + Debug > ( pub T , pub Child < T > , pub Child < T > ); #[derive(Clone, Debug)] pub struct BinaryTree < T : Clone + Copy + Debug > ( pub Node < T > ); In accordance to how the borrow check in rust works, it can not recurse on itself unless it's wrapped by an Rc or an Box . We're also going to be using it for all the implementations unless stated otherwise, to maintain consistency and focus on the algorithms themselves. The contained types must implement Copy, but that's just to make things a lot easier. In addition, we also use the following methods to make creating the trees easier: pub fn node2 < T : Clone + Copy + Debug > ( name : T , left : Node < T > , right : Node < T > ) -> Node < T > { Node ( name , Some ( Box :: new ( left )), Some ( Box :: new ( right ))) } pub fn node1r < T : Clone + Copy + Debug > ( name : T , right : Node < T > ) -> Node < T > { Node ( name , None , Some ( Box :: new ( right ))) } pub fn node1l < T : Clone + Copy + Debug > ( name : T , right : Node < T > ) -> Node < T > { Node ( name , Some ( Box :: new ( right )), None ) } pub fn node0 < T : Clone + Copy + Debug > ( name : T ) -> Node < T > { Node ( name , None , None ) } Tree Traversal Is the process of visiting (checking, updating) each node in a tree structure, exactly once. Unlike linked lists and arrays, which are usually traversed in linear order, trees may be traversed in two \"main\" ways: Breadth-first : check all the nodes on a certain level then going to the next one. Depth-first : check all the nodes in a certain \"lineage\", then come back and follow the other paths. Other algorithms are usually variations of those two types. The tree used for the tests is the following: graph TD F-->B B-->A B-->D D-->C D-->E F-->G G-->|right|I I-->|right|H With the helpers provided earlier, we can create it like this: BinaryTree ( node2 ( \"F\" , node2 ( \"B\" , node0 ( \"A\" ), node2 ( \"D\" , node0 ( \"C\" ), node0 ( \"E\" ))), node1r ( \"G\" , node1r ( \"I\" , node0 ( \"H\" ))), )); Unless specified otherwise, the Rust implementations will expose the same interface and can be tested with: traverse_tree ( tree , &|& node | { println ! ( \" -> {}\" , node ); }); Pre-order Traversal (root -> left -> right) Check if the current node is empty or null. Visit the root/current node. Traverse the left subtree, by recursively calling the function with the current node as the new root. Traverse the right subtree, by recursively calling the function with the current node as the new root. pub fn traverse_tree < T : Clone + Copy + Debug > ( tree : BinaryTree < T > , fun : & Fn ( & T )) { traverse ( & Some ( Box :: new ( tree . 0 )), fun ); } pub fn traverse < T : Clone + Copy + Debug > ( node : & Child < T > , fun : & Fn ( & T ) -> ()) { if let Some ( node ) = node { fun ( & node . 0 ); traverse ( & node . 1 , fun ); traverse ( & node . 2 , fun ); } } Result: -> F -> B -> A -> D -> C -> E -> G -> I -> H In-order Traversal (left -> root -> right) Check if the current node is empty or null. Traverse the left subtree, by recursively calling the function with the current node as the new root. Visit the root/current node. Traverse the right subtree, by recursively calling the function with the current node as the new root. pub fn traverse_tree < T : Clone + Copy + Debug > ( tree : BinaryTree < T > , fun : & Fn ( & T )) { traverse ( & Some ( Box :: new ( tree . 0 )), fun ); } pub fn traverse < T : Clone + Copy + Debug > ( node : & Child < T > , fun : & Fn ( & T ) -> ()) { if let Some ( node ) = node { traverse ( & node . 1 , fun ); fun ( & node . 0 ); traverse ( & node . 2 , fun ); } } Result: -> A -> B -> C -> D -> E -> F -> G -> I -> H Post-order Traversal (left -> right -> root) Check if the current node is empty or null. Traverse the left subtree, by recursively calling the function with the current node as the new root. Traverse the right subtree, by recursively calling the function with the current node as the new root. Visit the root/current node. pub fn traverse_tree < T : Clone + Copy + Debug > ( tree : BinaryTree < T > , fun : & Fn ( & T )) { traverse ( & Some ( Box :: new ( tree . 0 )), fun ); } pub fn traverse < T : Clone + Copy + Debug > ( node : & Child < T > , fun : & Fn ( & T ) -> ()) { if let Some ( node ) = node { traverse ( & node . 1 , fun ); traverse ( & node . 2 , fun ); fun ( & node . 0 ); } } Result: -> A -> C -> E -> D -> B -> H -> I -> G -> F Level-order Traversal To do the level-order traversal of the tree, we need a Queue, or some other form of collection that supports FIFO (First in, First out). For the Rust examples, I'm using the queues crate. Initialize an empty queue, and add the root to it. While the queue is not empty: Visit the node. If present, add left child to the queue. If present, add right child to the queue. pub fn traverse_tree < T : Clone + Copy + Debug > ( tree : BinaryTree < T > , fun : & Fn ( & T )) { traverse ( & Some ( Box :: new ( tree . 0 )), fun ); } pub fn traverse < T : Clone + Copy + Debug > ( node : & Child < T > , fun : & Fn ( & T ) -> ()) { if let Some ( node ) = node { let mut nodes = queue ! []; nodes . add ( node ); while let Ok ( top ) = nodes . remove () { fun ( & top . 0 ); if let Some ( ref left ) = top . 1 { nodes . add ( left ); }; if let Some ( ref right ) = top . 2 { nodes . add ( right ); }; } } } Reverse Level-order Traversal pub fn traverse_tree < T : Clone + Copy + Debug > ( tree : BinaryTree < T > , fun : & Fn ( & T )) { traverse ( & Some ( Box :: new ( tree . 0 )), fun ); } pub fn traverse < T : Clone + Copy + Debug > ( node : & Child < T > , fun : & Fn ( & T ) -> ()) { let mut queue : Queue <& Node < T >> = queue ! []; let mut stack : Vec <& Node < T >> = vec ! []; if let Some ( node ) = node { queue . add ( node ); while let Ok ( top ) = queue . remove () { // Remember to revert the order, as adding it left to right would // also invert the childs in the tree. if let Some ( ref right ) = top . 2 { queue . add ( right ); }; if let Some ( ref left ) = top . 1 { queue . add ( left ); }; stack . push ( top ); } } while let Some ( node ) = stack . pop () { fun ( & node . 0 ); } } Result: -> C -> E -> H -> A -> D -> I -> B -> G -> F References This amazing playlist by LucidProgramming","title":"Binary Trees"},{"location":"studies/programming/data_structures/binary_trees/#binary-trees","text":"A binary tree is a data structure where each node has 0, 1 or two children, referred to as left child and right child . A node without a parent is called a root , nodes without children are called leaves . Each node has 0-N ancestors , which refers to the parent chain up to the root, and descendants , in the direction of the leaves. The depth is the level of the node in comparison to the roots (root is lv1, both its children are lv2) and so on.","title":"Binary Trees"},{"location":"studies/programming/data_structures/binary_trees/#types-of-binary-trees","text":"Complete Tree: is a tree that is filled (as in, each node has at 2 nodes except for the leaves), and all the leaves in the last level are as far left as possible. graph TD 1 --> 2 1 --> 3 2 --> 4 2 --> 5 3 --> 6 3 --> 7 4 --> 8 Full Tree: is a tree in which every node has either 0 or 2 children. graph TD 1 --> 2 1 --> 3 2 --> 4 2 --> 5 3 --> 6 3 --> 7 Which can be represented with the following: pub type Child < T > = Option < Box < Node < T >>> ; #[derive(Clone, Debug)] pub struct Node < T : Clone + Copy + Debug > ( pub T , pub Child < T > , pub Child < T > ); #[derive(Clone, Debug)] pub struct BinaryTree < T : Clone + Copy + Debug > ( pub Node < T > ); In accordance to how the borrow check in rust works, it can not recurse on itself unless it's wrapped by an Rc or an Box . We're also going to be using it for all the implementations unless stated otherwise, to maintain consistency and focus on the algorithms themselves. The contained types must implement Copy, but that's just to make things a lot easier. In addition, we also use the following methods to make creating the trees easier: pub fn node2 < T : Clone + Copy + Debug > ( name : T , left : Node < T > , right : Node < T > ) -> Node < T > { Node ( name , Some ( Box :: new ( left )), Some ( Box :: new ( right ))) } pub fn node1r < T : Clone + Copy + Debug > ( name : T , right : Node < T > ) -> Node < T > { Node ( name , None , Some ( Box :: new ( right ))) } pub fn node1l < T : Clone + Copy + Debug > ( name : T , right : Node < T > ) -> Node < T > { Node ( name , Some ( Box :: new ( right )), None ) } pub fn node0 < T : Clone + Copy + Debug > ( name : T ) -> Node < T > { Node ( name , None , None ) }","title":"Types of Binary Trees"},{"location":"studies/programming/data_structures/binary_trees/#tree-traversal","text":"Is the process of visiting (checking, updating) each node in a tree structure, exactly once. Unlike linked lists and arrays, which are usually traversed in linear order, trees may be traversed in two \"main\" ways: Breadth-first : check all the nodes on a certain level then going to the next one. Depth-first : check all the nodes in a certain \"lineage\", then come back and follow the other paths. Other algorithms are usually variations of those two types. The tree used for the tests is the following: graph TD F-->B B-->A B-->D D-->C D-->E F-->G G-->|right|I I-->|right|H With the helpers provided earlier, we can create it like this: BinaryTree ( node2 ( \"F\" , node2 ( \"B\" , node0 ( \"A\" ), node2 ( \"D\" , node0 ( \"C\" ), node0 ( \"E\" ))), node1r ( \"G\" , node1r ( \"I\" , node0 ( \"H\" ))), )); Unless specified otherwise, the Rust implementations will expose the same interface and can be tested with: traverse_tree ( tree , &|& node | { println ! ( \" -> {}\" , node ); });","title":"Tree Traversal"},{"location":"studies/programming/data_structures/binary_trees/#pre-order-traversal-root-left-right","text":"Check if the current node is empty or null. Visit the root/current node. Traverse the left subtree, by recursively calling the function with the current node as the new root. Traverse the right subtree, by recursively calling the function with the current node as the new root. pub fn traverse_tree < T : Clone + Copy + Debug > ( tree : BinaryTree < T > , fun : & Fn ( & T )) { traverse ( & Some ( Box :: new ( tree . 0 )), fun ); } pub fn traverse < T : Clone + Copy + Debug > ( node : & Child < T > , fun : & Fn ( & T ) -> ()) { if let Some ( node ) = node { fun ( & node . 0 ); traverse ( & node . 1 , fun ); traverse ( & node . 2 , fun ); } } Result: -> F -> B -> A -> D -> C -> E -> G -> I -> H","title":"Pre-order Traversal (root -&gt; left -&gt; right)"},{"location":"studies/programming/data_structures/binary_trees/#in-order-traversal-left-root-right","text":"Check if the current node is empty or null. Traverse the left subtree, by recursively calling the function with the current node as the new root. Visit the root/current node. Traverse the right subtree, by recursively calling the function with the current node as the new root. pub fn traverse_tree < T : Clone + Copy + Debug > ( tree : BinaryTree < T > , fun : & Fn ( & T )) { traverse ( & Some ( Box :: new ( tree . 0 )), fun ); } pub fn traverse < T : Clone + Copy + Debug > ( node : & Child < T > , fun : & Fn ( & T ) -> ()) { if let Some ( node ) = node { traverse ( & node . 1 , fun ); fun ( & node . 0 ); traverse ( & node . 2 , fun ); } } Result: -> A -> B -> C -> D -> E -> F -> G -> I -> H","title":"In-order Traversal (left -&gt; root -&gt; right)"},{"location":"studies/programming/data_structures/binary_trees/#post-order-traversal-left-right-root","text":"Check if the current node is empty or null. Traverse the left subtree, by recursively calling the function with the current node as the new root. Traverse the right subtree, by recursively calling the function with the current node as the new root. Visit the root/current node. pub fn traverse_tree < T : Clone + Copy + Debug > ( tree : BinaryTree < T > , fun : & Fn ( & T )) { traverse ( & Some ( Box :: new ( tree . 0 )), fun ); } pub fn traverse < T : Clone + Copy + Debug > ( node : & Child < T > , fun : & Fn ( & T ) -> ()) { if let Some ( node ) = node { traverse ( & node . 1 , fun ); traverse ( & node . 2 , fun ); fun ( & node . 0 ); } } Result: -> A -> C -> E -> D -> B -> H -> I -> G -> F","title":"Post-order Traversal (left -&gt; right -&gt; root)"},{"location":"studies/programming/data_structures/binary_trees/#level-order-traversal","text":"To do the level-order traversal of the tree, we need a Queue, or some other form of collection that supports FIFO (First in, First out). For the Rust examples, I'm using the queues crate. Initialize an empty queue, and add the root to it. While the queue is not empty: Visit the node. If present, add left child to the queue. If present, add right child to the queue. pub fn traverse_tree < T : Clone + Copy + Debug > ( tree : BinaryTree < T > , fun : & Fn ( & T )) { traverse ( & Some ( Box :: new ( tree . 0 )), fun ); } pub fn traverse < T : Clone + Copy + Debug > ( node : & Child < T > , fun : & Fn ( & T ) -> ()) { if let Some ( node ) = node { let mut nodes = queue ! []; nodes . add ( node ); while let Ok ( top ) = nodes . remove () { fun ( & top . 0 ); if let Some ( ref left ) = top . 1 { nodes . add ( left ); }; if let Some ( ref right ) = top . 2 { nodes . add ( right ); }; } } }","title":"Level-order Traversal"},{"location":"studies/programming/data_structures/binary_trees/#reverse-level-order-traversal","text":"pub fn traverse_tree < T : Clone + Copy + Debug > ( tree : BinaryTree < T > , fun : & Fn ( & T )) { traverse ( & Some ( Box :: new ( tree . 0 )), fun ); } pub fn traverse < T : Clone + Copy + Debug > ( node : & Child < T > , fun : & Fn ( & T ) -> ()) { let mut queue : Queue <& Node < T >> = queue ! []; let mut stack : Vec <& Node < T >> = vec ! []; if let Some ( node ) = node { queue . add ( node ); while let Ok ( top ) = queue . remove () { // Remember to revert the order, as adding it left to right would // also invert the childs in the tree. if let Some ( ref right ) = top . 2 { queue . add ( right ); }; if let Some ( ref left ) = top . 1 { queue . add ( left ); }; stack . push ( top ); } } while let Some ( node ) = stack . pop () { fun ( & node . 0 ); } } Result: -> C -> E -> H -> A -> D -> I -> B -> G -> F","title":"Reverse Level-order Traversal"},{"location":"studies/programming/data_structures/binary_trees/#references","text":"This amazing playlist by LucidProgramming","title":"References"},{"location":"studies/programming/sorting/","text":"Index Index","title":"Index"},{"location":"studies/programming/sorting/#index","text":"Index","title":"Index"},{"location":"studies/programming/sorting/bubble_sort/","text":"Bubble Sort Bubble sort is a simple sorting algorithm used to teach sorting and algorithms in general to students, because of it's simplicity of concept and implementation. It has this name because of how the sorted elements \"bubble\" at the top of the list. It's average complexity is O(n^2) , which is the same as other, more efficient sorting algorithms, but they generally run faster because the number of swaps is much lower. There are ways to optimize the algorithm to make it faster, specially on already-sorted collections, but in general Insertion Sort should be used in those cases. Animation Complexity Best: \\mathcal{O}(n) \\\\ Average: \\mathcal{O}(n^2) \\\\ Worst: \\mathcal{O}(n^2) \\\\ Space: \\mathcal{O}(n) + \\mathcal{O}(1) Best: \\mathcal{O}(n) \\\\ Average: \\mathcal{O}(n^2) \\\\ Worst: \\mathcal{O}(n^2) \\\\ Space: \\mathcal{O}(n) + \\mathcal{O}(1) Because of how inefficient the algorithm is, the number of swaps can vary wildly: Best: \\mathcal{O}(1) \\\\ Average: \\mathcal{O}(n^2) \\\\ Worst: \\mathcal{O}(n^2) Best: \\mathcal{O}(1) \\\\ Average: \\mathcal{O}(n^2) \\\\ Worst: \\mathcal{O}(n^2) Pseudo-code i \u2190 0 while i < length(A) while j <(length(A) - 1) if A[j] > A[j + 1] swap A[j + 1] and A[j] end if j \u2190 j + 1 end while i \u2190 i + 1 end while Implementation pub fn sort < T : Ord > ( list : & mut Vec < T > ) { let len = list . len (); for _ in 0 .. len { for i in 0 ..( len - 1 ) { if list [ i ] > list [ i + 1 ] { list . swap ( i + 1 , i ); } } } }","title":"Bubble Sort"},{"location":"studies/programming/sorting/bubble_sort/#bubble-sort","text":"Bubble sort is a simple sorting algorithm used to teach sorting and algorithms in general to students, because of it's simplicity of concept and implementation. It has this name because of how the sorted elements \"bubble\" at the top of the list. It's average complexity is O(n^2) , which is the same as other, more efficient sorting algorithms, but they generally run faster because the number of swaps is much lower. There are ways to optimize the algorithm to make it faster, specially on already-sorted collections, but in general Insertion Sort should be used in those cases.","title":"Bubble Sort"},{"location":"studies/programming/sorting/bubble_sort/#animation","text":"","title":"Animation"},{"location":"studies/programming/sorting/bubble_sort/#complexity","text":"Best: \\mathcal{O}(n) \\\\ Average: \\mathcal{O}(n^2) \\\\ Worst: \\mathcal{O}(n^2) \\\\ Space: \\mathcal{O}(n) + \\mathcal{O}(1) Best: \\mathcal{O}(n) \\\\ Average: \\mathcal{O}(n^2) \\\\ Worst: \\mathcal{O}(n^2) \\\\ Space: \\mathcal{O}(n) + \\mathcal{O}(1) Because of how inefficient the algorithm is, the number of swaps can vary wildly: Best: \\mathcal{O}(1) \\\\ Average: \\mathcal{O}(n^2) \\\\ Worst: \\mathcal{O}(n^2) Best: \\mathcal{O}(1) \\\\ Average: \\mathcal{O}(n^2) \\\\ Worst: \\mathcal{O}(n^2)","title":"Complexity"},{"location":"studies/programming/sorting/bubble_sort/#pseudo-code","text":"i \u2190 0 while i < length(A) while j <(length(A) - 1) if A[j] > A[j + 1] swap A[j + 1] and A[j] end if j \u2190 j + 1 end while i \u2190 i + 1 end while","title":"Pseudo-code"},{"location":"studies/programming/sorting/bubble_sort/#implementation","text":"pub fn sort < T : Ord > ( list : & mut Vec < T > ) { let len = list . len (); for _ in 0 .. len { for i in 0 ..( len - 1 ) { if list [ i ] > list [ i + 1 ] { list . swap ( i + 1 , i ); } } } }","title":"Implementation"},{"location":"studies/programming/sorting/insertion_sort/","text":"Insertion Sort Insertion sort is very similar to Selection Sort, and as in it, after k passes on the loop, the first k elements are in sorted order. The difference however is that for selection sort, those are the k smallest elements in the unsorted input, while in selection sort they are simply the first k elements of the input. The advantage of this change is that selection sort must always scan all remaining elements to find the smallest one in the unsorted portion of the list, while insertion sort only requires a single comparison when the k + 1 th element is greater than the k th element. When this is frequently true, in cases where the list is fully or partially sorted, insertion sort requires about half as many comparisons as selection sort, while on the worst case (when the input is reverse-sorted), it has to do the same number of passes as selection sort. However, in general insertion sort writes to the list O(n^2) times, and selection sort will write only O(n) times, which makes it a bad option for cases where writing to memory is significantly more expensive than reading, such as when sorting things from disk. Animation Complexity Best: \\mathcal{O}(n) \\\\ Average: \\mathcal{O}(n^2) \\\\ Worst: \\mathcal{O}(n^2) \\\\ Space: \\mathcal{O}(n) + \\mathcal{O}(1) Best: \\mathcal{O}(n) \\\\ Average: \\mathcal{O}(n^2) \\\\ Worst: \\mathcal{O}(n^2) \\\\ Space: \\mathcal{O}(n) + \\mathcal{O}(1) Pseudo-code i \u2190 1 while i < length(A) j \u2190 i while j > 0 and A[j-1] > A[j] swap A[j] and A[j-1] j \u2190 j - 1 end while i \u2190 i + 1 end while Implementation pub fn sort < T : Ord > ( list : & mut Vec < T > ) { for i in 1 .. list . len () { let mut j = i ; while j > 0 && list [ j - 1 ] > list [ j ] { list . swap ( j , j - 1 ); j = j - 1 ; } } }","title":"Insertion Sort"},{"location":"studies/programming/sorting/insertion_sort/#insertion-sort","text":"Insertion sort is very similar to Selection Sort, and as in it, after k passes on the loop, the first k elements are in sorted order. The difference however is that for selection sort, those are the k smallest elements in the unsorted input, while in selection sort they are simply the first k elements of the input. The advantage of this change is that selection sort must always scan all remaining elements to find the smallest one in the unsorted portion of the list, while insertion sort only requires a single comparison when the k + 1 th element is greater than the k th element. When this is frequently true, in cases where the list is fully or partially sorted, insertion sort requires about half as many comparisons as selection sort, while on the worst case (when the input is reverse-sorted), it has to do the same number of passes as selection sort. However, in general insertion sort writes to the list O(n^2) times, and selection sort will write only O(n) times, which makes it a bad option for cases where writing to memory is significantly more expensive than reading, such as when sorting things from disk.","title":"Insertion Sort"},{"location":"studies/programming/sorting/insertion_sort/#animation","text":"","title":"Animation"},{"location":"studies/programming/sorting/insertion_sort/#complexity","text":"Best: \\mathcal{O}(n) \\\\ Average: \\mathcal{O}(n^2) \\\\ Worst: \\mathcal{O}(n^2) \\\\ Space: \\mathcal{O}(n) + \\mathcal{O}(1) Best: \\mathcal{O}(n) \\\\ Average: \\mathcal{O}(n^2) \\\\ Worst: \\mathcal{O}(n^2) \\\\ Space: \\mathcal{O}(n) + \\mathcal{O}(1)","title":"Complexity"},{"location":"studies/programming/sorting/insertion_sort/#pseudo-code","text":"i \u2190 1 while i < length(A) j \u2190 i while j > 0 and A[j-1] > A[j] swap A[j] and A[j-1] j \u2190 j - 1 end while i \u2190 i + 1 end while","title":"Pseudo-code"},{"location":"studies/programming/sorting/insertion_sort/#implementation","text":"pub fn sort < T : Ord > ( list : & mut Vec < T > ) { for i in 1 .. list . len () { let mut j = i ; while j > 0 && list [ j - 1 ] > list [ j ] { list . swap ( j , j - 1 ); j = j - 1 ; } } }","title":"Implementation"}]}